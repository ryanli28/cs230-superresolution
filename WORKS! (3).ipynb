{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3MxNMtbWqeff",
    "outputId": "521dc352-cfad-4741-8acb-b26cb369cd6f"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "print(torch.__version__) # 1.0.1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_imgs(x, new_fig=True):\n",
    "    grid = vutils.make_grid(x.detach().cpu(), nrow=8, normalize=True, pad_value=0.3)\n",
    "    grid = grid.transpose(0,2).transpose(0,1)\n",
    "    if new_fig:\n",
    "        plt.figure()\n",
    "    plt.imshow(grid.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_b5fVZBzq01k"
   },
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, inp_dim=262144):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(inp_dim, 512)\n",
    "        self.nonlin1 = nn.LeakyReLU(0.2)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 262144)\n",
    "        x = torch.FloatTensor(x)\n",
    "        h = self.nonlin1(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qbKUewFq2sC"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 512)\n",
    "        self.nonlin1 = nn.LeakyReLU(0.2)\n",
    "        self.fc2 = nn.Linear(512, 262144)\n",
    "    def forward(self, x):\n",
    "        h = self.nonlin1(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        out = torch.tanh(out)\n",
    "        out = out.view(out.size(0), 1, 512, 512)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "7d-sIZxMq5In",
    "outputId": "d270a218-2fef-4adb-90c0-13eeb4539823"
   },
   "outputs": [],
   "source": [
    "#probably should change from initial default, but we can fix for final proj not nec this milestone\n",
    "D = Discriminator()\n",
    "print(D)\n",
    "G = Generator()\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "4quJdwhBq6iq",
    "outputId": "8a7e9620-5301-4050-b833-135e2bee11bc"
   },
   "outputs": [],
   "source": [
    "samples = torch.randn(5, 1, 28, 28)\n",
    "D(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vZIviKWLq93Q",
    "outputId": "12de1a3e-20d7-4ef1-dc2e-978c152728cd"
   },
   "outputs": [],
   "source": [
    "for name, p in D.named_parameters():\n",
    "    print(name, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8VhlxOGXrEY6",
    "outputId": "fbdba3ef-029a-4b71-8131-9fa9e7fff326"
   },
   "outputs": [],
   "source": [
    "for name, p in G.named_parameters():\n",
    "    print(name, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "4SrmNXmFrHFC",
    "outputId": "44237c90-894b-42eb-daad-fad1c2d409b5"
   },
   "outputs": [],
   "source": [
    "z = torch.randn(2, 100)\n",
    "show_imgs(G(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ypeu2pu1rSAV"
   },
   "source": [
    "loading data & forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "1pevwUI0KGgv",
    "outputId": "15e7ce44-8382-4e4b-fe88-1b2febffcb6e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, low_res_file, high_res_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            low_res_file, high_res_file: text files containing paths to\n",
    "            the low resolution and high resolution images\n",
    "        \"\"\"\n",
    "        #lrf = np.loadtxt(low_res_file, dtype = str)\n",
    "        hrf = np.loadtxt(high_res_file, dtype = str)\n",
    "        self.imgs = hrf\n",
    "        #self.imgs = zip(lrf, hrf)\n",
    "        #print(len(list(self.imgs)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(list(self.imgs))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #low_res_path, high_res_path = list(self.imgs)[idx]\n",
    "        #print(\"HI\")\n",
    "        #lri, hri = np.load(low_res_path), np.load(high_res_path)\n",
    "        high_res_path = list(self.imgs)[idx]\n",
    "        hri = np.load(high_res_path)\n",
    "        #return lri, hri\n",
    "        return hri\n",
    "\n",
    "def get_loader(low_res_file, high_res_file, bs, shuffle):\n",
    "    mri_dataset = MRIDataset(low_res_file, high_res_file)\n",
    "    return DataLoader(mri_dataset, bs, shuffle)\n",
    "\n",
    "dataloader = get_loader(\"/Users/ryanli/Desktop/lr_file.txt\", \"/Users/ryanli/Desktop/hr_file.txt\", 64, False)\n",
    "#print(len(dataloader))\n",
    "import itertools\n",
    "\n",
    "#print(len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBTHTKDRrTFH"
   },
   "outputs": [],
   "source": [
    "#temp dataset - change this to dicom, but good bc made greyscle so sim to mri\n",
    "dataset = MRIDataset(\"/Users/ryanli/Desktop/lr_file.txt\", \"/Users/ryanli/Desktop/hr_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "VAY7NW2GrU3B",
    "outputId": "9dd9f0f2-033d-4c2d-d4f8-59f7ad538b9b"
   },
   "outputs": [],
   "source": [
    "ix=1000\n",
    "x = dataset.__getitem__(ix)\n",
    "x = torch.FloatTensor(x)\n",
    "print(x.view(x.size(0), 512))\n",
    "plt.matshow(np.squeeze(x), cmap=plt.cm.gray)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"low_res_example.png\")\n",
    "\n",
    "y = torch.FloatTensor(y)\n",
    "plt.matshow(np.squeeze(y), cmap=plt.cm.gray)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"high_res_example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "8afUgvzrrX4U",
    "outputId": "464e0973-28b4-4c0f-ccad-9b098aecd671"
   },
   "outputs": [],
   "source": [
    "#import itertools\n",
    "#Dscore = D(x)\n",
    "#print(len(iter(dataloader)))\n",
    "#lr_batch, hr_batch = next(itertools.cycle(dataloader))#.next() #minibatch\n",
    "#lr_batch.shape\n",
    "#D(lr_batch)\n",
    "#show_imgs(lr_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PohGZpaGriji"
   },
   "source": [
    "back to gans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "GYDi_bR1rjDj",
    "outputId": "4ddc93fe-2770-4875-da6e-17f49479525b"
   },
   "outputs": [],
   "source": [
    "#optimizers\n",
    "optimizerD = torch.optim.SGD(D.parameters(), lr=0.01)\n",
    "optimizerG = torch.optim.SGD(G.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SN3L73IWrk5l",
    "outputId": "daf019b5-be09-4de1-a6a9-98fcdf42d2ae"
   },
   "outputs": [],
   "source": [
    "#other notebook said taking this out improved acc - look into alter?\n",
    "criterion = nn.BCELoss()\n",
    "x_real, _ = enumerate(dataloader).next()\n",
    "print(x_real)\n",
    "lab_real = torch.ones(64, 1)\n",
    "lab_fake = torch.zeros(64, 1)\n",
    "optimizerD.zero_grad()\n",
    "\n",
    "D_x = D(x_real)\n",
    "lossD_real = criterion(D_x, lab_real)\n",
    "\n",
    "z = torch.randn(64, 100) #random noise but ?\n",
    "x_gen = G(z).detach()\n",
    "D_G_z = D(x_gen)\n",
    "lossD_fake = criterion(D_G_z, lab_fake)\n",
    "\n",
    "lossD = lossD_real + lossD_fake\n",
    "lossD.backward()\n",
    "optimizerD.step()\n",
    "\n",
    "# print(D_x.mean().item(), D_G_z.mean().item())\n",
    "optimizerG.zero_grad()\n",
    "\n",
    "z = torch.randn(64, 100) \n",
    "D_G_z = D(G(z))\n",
    "lossG = criterion(D_G_z, lab_real)\n",
    "\n",
    "lossG.backward()\n",
    "optimizerG.step()\n",
    "\n",
    "print(D_G_z.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OivGqsmGruQX",
    "outputId": "c37d029f-4674-4311-c0b5-3717c564f647"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Device: ', device)\n",
    "# Re-initialize D, G - not sure why?\n",
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "# other paper said rmsprops was better than adam - not sure how it stacks against sgd - look into for final\n",
    "optimizerD = torch.optim.SGD(D.parameters(), lr=0.2)\n",
    "optimizerG = torch.optim.SGD(G.parameters(), lr=0.2)\n",
    "# optimizerD = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "# optimizerG = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "lab_real = torch.ones(64, 1, device=device)\n",
    "lab_fake = torch.zeros(64, 1, device=device)\n",
    "\n",
    "\n",
    "collect_x_gen = []\n",
    "fixed_noise = torch.randn(64, 100, device=device)\n",
    "fig = plt.figure() \n",
    "plt.ion()\n",
    "\n",
    "for epoch in range(2): # 10 epochs\n",
    "    #for i, (lri, hri) in enumerate(dataloader, 0):\n",
    "    for i in range(0, 21):\n",
    "        x_real = next(iter(dataloader)).float()\n",
    "        x_real = x_real.to(device)\n",
    "        optimizerD.zero_grad()\n",
    "        x_real = torch.FloatTensor(x_real)\n",
    "        \n",
    "        D_x = D(x_real)\n",
    "        lossD_real = criterion(D_x, lab_real)\n",
    "\n",
    "        z = torch.randn(64, 100, device=device)\n",
    "        x_gen = G(z).detach()\n",
    "        D_G_z = D(x_gen)\n",
    "        lossD_fake = criterion(D_G_z, lab_fake)\n",
    "\n",
    "        lossD = lossD_real + lossD_fake\n",
    "        lossD.backward()\n",
    "        optimizerD.step()\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        z = torch.randn(64, 100, device=device) \n",
    "        x_gen = G(z)\n",
    "        D_G_z = D(x_gen)\n",
    "        lossG = criterion(D_G_z, lab_real)\n",
    "\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        if i % 100 == 0:\n",
    "            x_gen = G(fixed_noise)\n",
    "            show_imgs(x_gen, new_fig=False)\n",
    "            fig.canvas.draw()\n",
    "            print('e{}.i{}/{} last mb D(x)={:.4f} D(G(z))={:.4f}'.format(\n",
    "                epoch, i, 21, D_x.mean().item(), D_G_z.mean().item()))\n",
    "    #epoch end\n",
    "    x_gen = G(fixed_noise)\n",
    "    collect_x_gen.append(x_gen.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "id": "i1xyYmD9rvYB",
    "outputId": "d1577e0b-d5af-4a21-ef51-1572aafd1feb"
   },
   "outputs": [],
   "source": [
    "for x_gen in collect_x_gen:\n",
    "    show_imgs(x_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WORKS!",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
